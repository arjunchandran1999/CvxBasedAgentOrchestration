{"event": "job_start", "ts_ms": 1772063810428.0137, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-1", "query": "WorkflowBench job wb1", "gpu_name": "NVIDIA A100 80GB PCIe", "gpu_uuid": "GPU-68a0d6f9-97b4-8e27-fbb7-a234eaefd1a8", "benchmark_name": "workflowbench", "routing_mode": "lp", "lambda_token": 0.5, "lambda_switch": 0.2, "gpu_vram_gb": 8.0, "vram_used_gb": 0.0, "vram_violation": false, "loaded_models_before": [], "active_models": [], "active_roles": [], "active_role_agents": [], "n_distinct_models": 0, "n_role_agents": 0, "models_swapped_in": [], "estimated_switch_cost_ms": 0.0, "sum_token_cost": 0.0, "job_score": null, "token_scale": 1000.0, "switch_t_scale_ms": 1500.0}
{"event": "dag_structure", "ts_ms": 1772063810432.706, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-1", "benchmark_name": "workflowbench", "mpc": true, "horizon_depth": 1, "nodes": [{"id": "s0", "task_type": "extraction", "difficulty": 1.5}, {"id": "s1", "task_type": "math", "difficulty": 2.0}, {"id": "s2", "task_type": "code", "difficulty": 2.0}], "edges": [["s0", "s1"], ["s1", "s2"]]}
{"event": "subtask_plan", "ts_ms": 1772063810436.5437, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-1", "benchmark_name": "workflowbench", "routing_mode": "lp", "plan_source": "benchmark_dag", "subtasks": [{"id": "s0", "task_type": "extraction", "description": "From the text 'A=3 and B=4', extract JSON {\"A\":3,\"B\":4}. Return ONLY JSON.", "estimated_tokens": 200, "difficulty": 1.5}, {"id": "s1", "task_type": "math", "description": "Given A=3 and B=4, compute A^2 + B^2. Output only the number.", "estimated_tokens": 150, "difficulty": 2.0}, {"id": "s2", "task_type": "code", "description": "Write Python: def hyp_sq(a,b): return a*a + b*b. Return ONLY code.", "estimated_tokens": 350, "difficulty": 2.0}]}
{"event": "plan_step", "ts_ms": 1772063810537.5615, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-1", "plan_step_index": 0, "routing_mode": "lp", "mpc": true, "horizon_depth": 1, "horizon_nodes": ["s0", "s1"], "ready_now_nodes": ["s0"], "active_models_before": [], "gpu_vram_gb": 8.0, "lp_dpp_enabled": true, "lp_solver_name": "HIGHS", "lp_solve_status": "optimal", "lp_solve_time_ms": 11.877059936523438, "lp_objective_value": 0.8716666666666666, "assignments": [{"subtask_id": "s0", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.6699999999999999, "estimated_token_cost": 280.0, "estimated_switch_cost_share": 1.0666666666666667}, {"subtask_id": "s1", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.6599999999999999, "estimated_token_cost": 210.0, "estimated_switch_cost_share": 1.0666666666666667}], "executed_assignments": [{"subtask_id": "s0", "assigned_agent": "llama3.1:8b"}], "step_vram_gb": 8.0}
{"event": "orchestration", "ts_ms": 1772063810541.348, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-1", "benchmark_name": "workflowbench", "routing_mode": "lp", "routing_source": "lp", "planner_model": null, "assignments": [{"subtask_id": "s0", "role": "extraction", "model": "llama3.1:8b", "agent_id": "extraction|llama3.1:8b"}], "active_models": ["llama3.1:8b"], "active_role_agents": ["extraction|llama3.1:8b"]}
{"event": "subtask", "ts_ms": 1772063814789.3518, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-1", "subtask_id": "s0", "task_type": "extraction", "difficulty": 1.5, "estimated_tokens": 200, "assigned_agent": "llama3.1:8b", "agent_id": "extraction|llama3.1:8b", "routing_mode": "lp", "estimated_performance": 0.6699999999999999, "estimated_token_cost": 280.0, "estimated_switch_cost_norm": 1.0666666666666667, "swapped_in_for_job": true, "actual_latency_ms": 4243.948884308338, "input_tokens": 74, "output_tokens": 13, "judge_score": null, "benchmark_name": "workflowbench", "benchmark_score": null, "success": true, "error": null, "output": "{\"A\": 3, \"B\": 4}"}
{"event": "plan_step", "ts_ms": 1772063814799.6863, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-1", "plan_step_index": 1, "routing_mode": "lp", "mpc": true, "horizon_depth": 1, "horizon_nodes": ["s0", "s1", "s2"], "ready_now_nodes": ["s1"], "active_models_before": ["llama3.1:8b"], "gpu_vram_gb": 8.0, "lp_dpp_enabled": true, "lp_solver_name": "HIGHS", "lp_solve_status": "optimal", "lp_solve_time_ms": 0.8342266082763672, "lp_objective_value": 1.54, "assignments": [{"subtask_id": "s0", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.73, "estimated_token_cost": 280.0, "estimated_switch_cost_share": 0.0}, {"subtask_id": "s1", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.6599999999999999, "estimated_token_cost": 210.0, "estimated_switch_cost_share": 0.0}, {"subtask_id": "s2", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.6399999999999999, "estimated_token_cost": 489.99999999999994, "estimated_switch_cost_share": 0.0}], "executed_assignments": [{"subtask_id": "s1", "assigned_agent": "llama3.1:8b"}], "step_vram_gb": 8.0}
{"event": "orchestration", "ts_ms": 1772063814808.574, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-1", "benchmark_name": "workflowbench", "routing_mode": "lp", "routing_source": "lp", "planner_model": null, "assignments": [{"subtask_id": "s1", "role": "math", "model": "llama3.1:8b", "agent_id": "math|llama3.1:8b"}], "active_models": ["llama3.1:8b"], "active_role_agents": ["math|llama3.1:8b"]}
{"event": "subtask", "ts_ms": 1772063815942.0974, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-1", "subtask_id": "s1", "task_type": "math", "difficulty": 2.0, "estimated_tokens": 150, "assigned_agent": "llama3.1:8b", "agent_id": "math|llama3.1:8b", "routing_mode": "lp", "estimated_performance": 0.6599999999999999, "estimated_token_cost": 210.0, "estimated_switch_cost_norm": 0.0, "swapped_in_for_job": false, "actual_latency_ms": 1129.360917955637, "input_tokens": 73, "output_tokens": 132, "judge_score": null, "benchmark_name": "workflowbench", "benchmark_score": null, "success": true, "error": null, "output": "To solve this problem, I will follow these steps:\n\n1. Compute A^2\nA = 3\nA^2 = A × A\n= 3 × 3\n= 9\n\n2. Compute B^2\nB = 4\nB^2 = B × B\n= 4 × 4\n= 16\n\n3. Add the results of step 1 and step 2\nA^2 + B^2 = 9 + 16\n= 25\n\nTherefore, the final answer is:\n\n**25**\n\nThis result will be output as a number only, as per the problem statement."}
{"event": "plan_step", "ts_ms": 1772063815952.8909, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-1", "plan_step_index": 2, "routing_mode": "lp", "mpc": true, "horizon_depth": 1, "horizon_nodes": ["s0", "s1", "s2"], "ready_now_nodes": ["s2"], "active_models_before": ["llama3.1:8b"], "gpu_vram_gb": 8.0, "lp_dpp_enabled": true, "lp_solver_name": "HIGHS", "lp_solve_status": "optimal", "lp_solve_time_ms": 0.8609294891357422, "lp_objective_value": 1.596, "assignments": [{"subtask_id": "s0", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.73, "estimated_token_cost": 280.0, "estimated_switch_cost_share": 0.0}, {"subtask_id": "s1", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.716, "estimated_token_cost": 210.0, "estimated_switch_cost_share": 0.0}, {"subtask_id": "s2", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.6399999999999999, "estimated_token_cost": 489.99999999999994, "estimated_switch_cost_share": 0.0}], "executed_assignments": [{"subtask_id": "s2", "assigned_agent": "llama3.1:8b"}], "step_vram_gb": 8.0}
{"event": "orchestration", "ts_ms": 1772063815956.4258, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-1", "benchmark_name": "workflowbench", "routing_mode": "lp", "routing_source": "lp", "planner_model": null, "assignments": [{"subtask_id": "s2", "role": "code", "model": "llama3.1:8b", "agent_id": "code|llama3.1:8b"}], "active_models": ["llama3.1:8b"], "active_role_agents": ["code|llama3.1:8b"]}
{"event": "subtask", "ts_ms": 1772063816318.0344, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-1", "subtask_id": "s2", "task_type": "code", "difficulty": 2.0, "estimated_tokens": 350, "assigned_agent": "llama3.1:8b", "agent_id": "code|llama3.1:8b", "routing_mode": "lp", "estimated_performance": 0.6399999999999999, "estimated_token_cost": 489.99999999999994, "estimated_switch_cost_norm": 0.0, "swapped_in_for_job": false, "actual_latency_ms": 357.44153149425983, "input_tokens": 73, "output_tokens": 22, "judge_score": null, "benchmark_name": "workflowbench", "benchmark_score": null, "success": true, "error": null, "output": "```python\ndef hyp_sq(a, b):\n    return a**2 + b**2\n```"}
{"event": "job", "ts_ms": 1772063816323.5137, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-1", "query": "WorkflowBench job wb1", "gpu_name": "NVIDIA A100 80GB PCIe", "gpu_uuid": "GPU-68a0d6f9-97b4-8e27-fbb7-a234eaefd1a8", "benchmark_name": "workflowbench", "routing_mode": "lp", "lambda_token": 0.5, "lambda_switch": 0.2, "gpu_vram_gb": 8.0, "vram_used_gb": 8.0, "vram_violation": false, "loaded_models_before": [], "active_models": ["llama3.1:8b"], "active_roles": ["code", "extraction", "math"], "active_role_agents": ["code|llama3.1:8b", "extraction|llama3.1:8b", "math|llama3.1:8b"], "n_distinct_models": 1, "n_role_agents": 3, "models_swapped_in": ["llama3.1:8b"], "estimated_switch_cost_ms": 1600.0, "sum_token_cost": 0.0, "job_score": 1.0, "token_scale": 1000.0, "switch_t_scale_ms": 1500.0}
{"event": "job_costs", "ts_ms": 1772063816327.2974, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-1", "query": "WorkflowBench job wb1", "gpu_name": "NVIDIA A100 80GB PCIe", "gpu_uuid": "GPU-68a0d6f9-97b4-8e27-fbb7-a234eaefd1a8", "benchmark_name": "workflowbench", "routing_mode": "lp", "lambda_token": 0.5, "lambda_switch": 0.2, "gpu_vram_gb": 8.0, "vram_used_gb": 8.0, "vram_violation": false, "loaded_models_before": [], "active_models": ["llama3.1:8b"], "active_roles": ["code", "extraction", "math"], "active_role_agents": ["code|llama3.1:8b", "extraction|llama3.1:8b", "math|llama3.1:8b"], "n_distinct_models": 1, "n_role_agents": 3, "models_swapped_in": ["llama3.1:8b"], "estimated_switch_cost_ms": 1600.0, "sum_token_cost": 541.8, "job_score": 1.0, "token_scale": 1000.0, "switch_t_scale_ms": 1500.0}
{"event": "job_dag_summary", "ts_ms": 1772063816331.3958, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-1", "benchmark_name": "workflowbench", "routing_mode": "lp", "quality_estimator_type": "static", "is_dag": true, "mpc": true, "horizon_depth": 1, "n_nodes": 3, "n_edges": 2, "n_layers": 3, "n_plan_steps": 3, "vram_peak_gb": 8.0, "peak_vram_used_gb": 8.0, "vram_distinct_gb": 8.0, "total_latency_ms": 5730.751333758235, "total_token_cost": 541.8, "total_switch_cost_est": 1600.0, "avg_subtask_score": 1.0, "job_score": 1.0, "job_success": true, "lp_solver_name": "HIGHS", "lp_solve_time_ms_avg": 4.5241}
{"event": "job_start", "ts_ms": 1772063816353.0469, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-2", "query": "WorkflowBench job wb2", "gpu_name": "NVIDIA A100 80GB PCIe", "gpu_uuid": "GPU-68a0d6f9-97b4-8e27-fbb7-a234eaefd1a8", "benchmark_name": "workflowbench", "routing_mode": "lp", "lambda_token": 0.5, "lambda_switch": 0.2, "gpu_vram_gb": 8.0, "vram_used_gb": 0.0, "vram_violation": false, "loaded_models_before": ["llama3.1:8b"], "active_models": [], "active_roles": [], "active_role_agents": [], "n_distinct_models": 0, "n_role_agents": 0, "models_swapped_in": [], "estimated_switch_cost_ms": 0.0, "sum_token_cost": 0.0, "job_score": null, "token_scale": 1000.0, "switch_t_scale_ms": 1500.0}
{"event": "dag_structure", "ts_ms": 1772063816356.737, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-2", "benchmark_name": "workflowbench", "mpc": true, "horizon_depth": 1, "nodes": [{"id": "s0", "task_type": "code", "difficulty": 3.0}, {"id": "s1", "task_type": "math", "difficulty": 2.0}, {"id": "s2", "task_type": "summarize", "difficulty": 2.0}], "edges": [["s0", "s1"], ["s0", "s2"]]}
{"event": "subtask_plan", "ts_ms": 1772063816360.1003, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-2", "benchmark_name": "workflowbench", "routing_mode": "lp", "plan_source": "benchmark_dag", "subtasks": [{"id": "s0", "task_type": "code", "description": "Write Python: def fib(n): return nth Fibonacci with fib(0)=0,fib(1)=1. Return ONLY code.", "estimated_tokens": 450, "difficulty": 3.0}, {"id": "s1", "task_type": "math", "description": "Compute fib(10) if fib(0)=0, fib(1)=1. Output only the number.", "estimated_tokens": 120, "difficulty": 2.0}, {"id": "s2", "task_type": "summarize", "description": "In 1-2 sentences, explain how Fibonacci works (recurrence).", "estimated_tokens": 180, "difficulty": 2.0}]}
{"event": "plan_step", "ts_ms": 1772063816368.2559, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-2", "plan_step_index": 0, "routing_mode": "lp", "mpc": true, "horizon_depth": 1, "horizon_nodes": ["s0", "s1", "s2"], "ready_now_nodes": ["s0"], "active_models_before": ["llama3.1:8b"], "gpu_vram_gb": 8.0, "lp_dpp_enabled": true, "lp_solver_name": "HIGHS", "lp_solve_status": "optimal", "lp_solve_time_ms": 0.8320808410644531, "lp_objective_value": 1.521, "assignments": [{"subtask_id": "s0", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.64, "estimated_token_cost": 630.0, "estimated_switch_cost_share": 0.0}, {"subtask_id": "s1", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.716, "estimated_token_cost": 168.0, "estimated_switch_cost_share": 0.0}, {"subtask_id": "s2", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.69, "estimated_token_cost": 251.99999999999994, "estimated_switch_cost_share": 0.0}], "executed_assignments": [{"subtask_id": "s0", "assigned_agent": "llama3.1:8b"}], "step_vram_gb": 8.0}
{"event": "orchestration", "ts_ms": 1772063816372.2068, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-2", "benchmark_name": "workflowbench", "routing_mode": "lp", "routing_source": "lp", "planner_model": null, "assignments": [{"subtask_id": "s0", "role": "code", "model": "llama3.1:8b", "agent_id": "code|llama3.1:8b"}], "active_models": ["llama3.1:8b"], "active_role_agents": ["code|llama3.1:8b"]}
{"event": "subtask", "ts_ms": 1772063817059.1396, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-2", "subtask_id": "s0", "task_type": "code", "difficulty": 3.0, "estimated_tokens": 450, "assigned_agent": "llama3.1:8b", "agent_id": "code|llama3.1:8b", "routing_mode": "lp", "estimated_performance": 0.64, "estimated_token_cost": 630.0, "estimated_switch_cost_norm": 0.0, "swapped_in_for_job": false, "actual_latency_ms": 682.6729159802198, "input_tokens": 80, "output_tokens": 68, "judge_score": null, "benchmark_name": "workflowbench", "benchmark_score": null, "success": true, "error": null, "output": "```python\ndef fib(n):\n    if n <= 1:\n        return n\n    else:\n        return fib(n-1) + fib(n-2)\n```\n\nThis function uses recursion to calculate the nth Fibonacci number, where `fib(0)` returns `0` and `fib(1)` returns `1`."}
{"event": "plan_step", "ts_ms": 1772063817069.281, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-2", "plan_step_index": 1, "routing_mode": "lp", "mpc": true, "horizon_depth": 1, "horizon_nodes": ["s0", "s1", "s2"], "ready_now_nodes": ["s1", "s2"], "active_models_before": ["llama3.1:8b"], "gpu_vram_gb": 8.0, "lp_dpp_enabled": true, "lp_solver_name": "HIGHS", "lp_solve_status": "optimal", "lp_solve_time_ms": 0.6763935089111328, "lp_objective_value": 1.569, "assignments": [{"subtask_id": "s0", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.6880000000000001, "estimated_token_cost": 630.0, "estimated_switch_cost_share": 0.0}, {"subtask_id": "s1", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.716, "estimated_token_cost": 168.0, "estimated_switch_cost_share": 0.0}, {"subtask_id": "s2", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.69, "estimated_token_cost": 251.99999999999994, "estimated_switch_cost_share": 0.0}], "executed_assignments": [{"subtask_id": "s1", "assigned_agent": "llama3.1:8b"}, {"subtask_id": "s2", "assigned_agent": "llama3.1:8b"}], "step_vram_gb": 8.0}
{"event": "orchestration", "ts_ms": 1772063817073.0361, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-2", "benchmark_name": "workflowbench", "routing_mode": "lp", "routing_source": "lp", "planner_model": null, "assignments": [{"subtask_id": "s1", "role": "math", "model": "llama3.1:8b", "agent_id": "math|llama3.1:8b"}, {"subtask_id": "s2", "role": "summarize", "model": "llama3.1:8b", "agent_id": "summarize|llama3.1:8b"}], "active_models": ["llama3.1:8b"], "active_role_agents": ["math|llama3.1:8b", "summarize|llama3.1:8b"]}
{"event": "subtask", "ts_ms": 1772063821073.728, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-2", "subtask_id": "s1", "task_type": "math", "difficulty": 2.0, "estimated_tokens": 120, "assigned_agent": "llama3.1:8b", "agent_id": "math|llama3.1:8b", "routing_mode": "lp", "estimated_performance": 0.716, "estimated_token_cost": 168.0, "estimated_switch_cost_norm": 0.0, "swapped_in_for_job": false, "actual_latency_ms": 3996.514018625021, "input_tokens": 73, "output_tokens": 470, "judge_score": null, "benchmark_name": "workflowbench", "benchmark_score": null, "success": true, "error": null, "output": "A delightful math problem!\n\nTo compute `fib(10)` using the recurrence relation `fib(n) = fib(n-1) + fib(n-2)` with base cases `fib(0) = 0` and `fib(1) = 1`, I'll use a step-by-step approach.\n\n**Step 1: Initialize variables**\n\nLet's define the first two values of the Fibonacci sequence:\n\n* `fib(0) = 0`\n* `fib(1) = 1`\n\nWe need to compute `fib(10)` using these base cases.\n\n**Step 2: Compute fib(2)**\n\nUsing the recurrence relation, we can compute `fib(2)` as follows:\n`fib(2) = fib(1) + fib(0)`\n= `1 + 0`\n= `1`\n\nSo, `fib(2) = 1`.\n\n**Step 3: Compute fib(3)**\n\nNow, let's compute `fib(3)` using the recurrence relation again:\n`fib(3) = fib(2) + fib(1)`\n= `1 + 1`\n= `2`\n\nSo, `fib(3) = 2`.\n\n**Step 4: Continue computing Fibonacci numbers up to fib(10)**\n\nWe'll continue this process iteratively:\n\n* `fib(4) = fib(3) + fib(2) = 2 + 1 = 3`\n* `fib(5) = fib(4) + fib(3) = 3 + 2 = 5`\n* `fib(6) = fib(5) + fib(4) = 5 + 3 = 8`\n* `fib(7) = fib(6) + fib(5) = 8 + 5 = 13`\n* `fib(8) = fib(7) + fib(6) = 13 + 8 = 21`\n* `fib(9) = fib(8) + fib(7) = 21 + 13 = 34`\n* `fib(10) = fib(9) + fib(8) = 34 + 21 = 55`\n\n**Final answer:**\n\nThe value of `fib(10)` is **55**."}
{"event": "subtask", "ts_ms": 1772063821079.2146, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-2", "subtask_id": "s2", "task_type": "summarize", "difficulty": 2.0, "estimated_tokens": 180, "assigned_agent": "llama3.1:8b", "agent_id": "summarize|llama3.1:8b", "routing_mode": "lp", "estimated_performance": 0.69, "estimated_token_cost": 251.99999999999994, "estimated_switch_cost_norm": 0.0, "swapped_in_for_job": false, "actual_latency_ms": 641.0206668078899, "input_tokens": 62, "output_tokens": 59, "judge_score": null, "benchmark_name": "workflowbench", "benchmark_score": null, "success": true, "error": null, "output": "The Fibonacci sequence is a series of numbers where each number is the sum of the two preceding ones, starting with 0 and 1. This creates a recursive relationship: F(n) = F(n-1) + F(n-2), where n represents the position in the sequence."}
{"event": "job", "ts_ms": 1772063821082.9048, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-2", "query": "WorkflowBench job wb2", "gpu_name": "NVIDIA A100 80GB PCIe", "gpu_uuid": "GPU-68a0d6f9-97b4-8e27-fbb7-a234eaefd1a8", "benchmark_name": "workflowbench", "routing_mode": "lp", "lambda_token": 0.5, "lambda_switch": 0.2, "gpu_vram_gb": 8.0, "vram_used_gb": 8.0, "vram_violation": false, "loaded_models_before": ["llama3.1:8b"], "active_models": ["llama3.1:8b"], "active_roles": ["code", "math", "summarize"], "active_role_agents": ["code|llama3.1:8b", "math|llama3.1:8b", "summarize|llama3.1:8b"], "n_distinct_models": 1, "n_role_agents": 3, "models_swapped_in": [], "estimated_switch_cost_ms": 0.0, "sum_token_cost": 0.0, "job_score": 0.8888888888888888, "token_scale": 1000.0, "switch_t_scale_ms": 1500.0}
{"event": "job_costs", "ts_ms": 1772063821086.216, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-2", "query": "WorkflowBench job wb2", "gpu_name": "NVIDIA A100 80GB PCIe", "gpu_uuid": "GPU-68a0d6f9-97b4-8e27-fbb7-a234eaefd1a8", "benchmark_name": "workflowbench", "routing_mode": "lp", "lambda_token": 0.5, "lambda_switch": 0.2, "gpu_vram_gb": 8.0, "vram_used_gb": 8.0, "vram_violation": false, "loaded_models_before": ["llama3.1:8b"], "active_models": ["llama3.1:8b"], "active_roles": ["code", "math", "summarize"], "active_role_agents": ["code|llama3.1:8b", "math|llama3.1:8b", "summarize|llama3.1:8b"], "n_distinct_models": 1, "n_role_agents": 3, "models_swapped_in": [], "estimated_switch_cost_ms": 0.0, "sum_token_cost": 1136.7999999999997, "job_score": 0.8888888888888888, "token_scale": 1000.0, "switch_t_scale_ms": 1500.0}
{"event": "job_dag_summary", "ts_ms": 1772063821089.4736, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-2", "benchmark_name": "workflowbench", "routing_mode": "lp", "quality_estimator_type": "static", "is_dag": true, "mpc": true, "horizon_depth": 1, "n_nodes": 3, "n_edges": 2, "n_layers": 2, "n_plan_steps": 2, "vram_peak_gb": 8.0, "peak_vram_used_gb": 8.0, "vram_distinct_gb": 8.0, "total_latency_ms": 5320.207601413131, "total_token_cost": 1136.7999999999997, "total_switch_cost_est": 0.0, "avg_subtask_score": 0.8888888888888888, "job_score": 0.8888888888888888, "job_success": true, "lp_solver_name": "HIGHS", "lp_solve_time_ms_avg": 0.7542}
{"event": "job_start", "ts_ms": 1772063821110.1265, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-3", "query": "WorkflowBench job wb3", "gpu_name": "NVIDIA A100 80GB PCIe", "gpu_uuid": "GPU-68a0d6f9-97b4-8e27-fbb7-a234eaefd1a8", "benchmark_name": "workflowbench", "routing_mode": "lp", "lambda_token": 0.5, "lambda_switch": 0.2, "gpu_vram_gb": 8.0, "vram_used_gb": 0.0, "vram_violation": false, "loaded_models_before": ["llama3.1:8b"], "active_models": [], "active_roles": [], "active_role_agents": [], "n_distinct_models": 0, "n_role_agents": 0, "models_swapped_in": [], "estimated_switch_cost_ms": 0.0, "sum_token_cost": 0.0, "job_score": null, "token_scale": 1000.0, "switch_t_scale_ms": 1500.0}
{"event": "dag_structure", "ts_ms": 1772063821113.243, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-3", "benchmark_name": "workflowbench", "mpc": true, "horizon_depth": 1, "nodes": [{"id": "s0", "task_type": "extraction", "difficulty": 1.5}, {"id": "s1", "task_type": "reasoning", "difficulty": 2.5}, {"id": "s2", "task_type": "summarize", "difficulty": 1.5}], "edges": [["s0", "s1"], ["s1", "s2"]]}
{"event": "subtask_plan", "ts_ms": 1772063821116.99, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-3", "benchmark_name": "workflowbench", "routing_mode": "lp", "plan_source": "benchmark_dag", "subtasks": [{"id": "s0", "task_type": "extraction", "description": "Extract the date from: 'Meeting is on 2026-02-21.' Return ONLY JSON {\"date\": \"YYYY-MM-DD\"}.", "estimated_tokens": 180, "difficulty": 1.5}, {"id": "s1", "task_type": "reasoning", "description": "Is 2026-02-21 a Saturday? Answer YES or NO only.", "estimated_tokens": 120, "difficulty": 2.5}, {"id": "s2", "task_type": "summarize", "description": "Summarize the result in one short sentence.", "estimated_tokens": 120, "difficulty": 1.5}]}
{"event": "plan_step", "ts_ms": 1772063821123.9016, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-3", "plan_step_index": 0, "routing_mode": "lp", "mpc": true, "horizon_depth": 1, "horizon_nodes": ["s0", "s1"], "ready_now_nodes": ["s0"], "active_models_before": ["llama3.1:8b"], "gpu_vram_gb": 8.0, "lp_dpp_enabled": true, "lp_solver_name": "HIGHS", "lp_solve_status": "optimal", "lp_solve_time_ms": 0.74005126953125, "lp_objective_value": 1.23, "assignments": [{"subtask_id": "s0", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.73, "estimated_token_cost": 251.99999999999994, "estimated_switch_cost_share": 0.0}, {"subtask_id": "s1", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.7100000000000001, "estimated_token_cost": 168.0, "estimated_switch_cost_share": 0.0}], "executed_assignments": [{"subtask_id": "s0", "assigned_agent": "llama3.1:8b"}], "step_vram_gb": 8.0}
{"event": "orchestration", "ts_ms": 1772063821127.0725, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-3", "benchmark_name": "workflowbench", "routing_mode": "lp", "routing_source": "lp", "planner_model": null, "assignments": [{"subtask_id": "s0", "role": "extraction", "model": "llama3.1:8b", "agent_id": "extraction|llama3.1:8b"}], "active_models": ["llama3.1:8b"], "active_role_agents": ["extraction|llama3.1:8b"]}
{"event": "subtask", "ts_ms": 1772063821438.9885, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-3", "subtask_id": "s0", "task_type": "extraction", "difficulty": 1.5, "estimated_tokens": 180, "assigned_agent": "llama3.1:8b", "agent_id": "extraction|llama3.1:8b", "routing_mode": "lp", "estimated_performance": 0.73, "estimated_token_cost": 251.99999999999994, "estimated_switch_cost_norm": 0.0, "swapped_in_for_job": false, "actual_latency_ms": 308.71376395225525, "input_tokens": 76, "output_tokens": 12, "judge_score": null, "benchmark_name": "workflowbench", "benchmark_score": null, "success": true, "error": null, "output": "{\"date\": \"2026-02-21\"}"}
{"event": "plan_step", "ts_ms": 1772063821448.076, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-3", "plan_step_index": 1, "routing_mode": "lp", "mpc": true, "horizon_depth": 1, "horizon_nodes": ["s0", "s1", "s2"], "ready_now_nodes": ["s1"], "active_models_before": ["llama3.1:8b"], "gpu_vram_gb": 8.0, "lp_dpp_enabled": true, "lp_solver_name": "HIGHS", "lp_solve_status": "optimal", "lp_solve_time_ms": 0.8027553558349609, "lp_objective_value": 1.964, "assignments": [{"subtask_id": "s0", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.778, "estimated_token_cost": 251.99999999999994, "estimated_switch_cost_share": 0.0}, {"subtask_id": "s1", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.7100000000000001, "estimated_token_cost": 168.0, "estimated_switch_cost_share": 0.0}, {"subtask_id": "s2", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.77, "estimated_token_cost": 168.0, "estimated_switch_cost_share": 0.0}], "executed_assignments": [{"subtask_id": "s1", "assigned_agent": "llama3.1:8b"}], "step_vram_gb": 8.0}
{"event": "orchestration", "ts_ms": 1772063821451.7732, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-3", "benchmark_name": "workflowbench", "routing_mode": "lp", "routing_source": "lp", "planner_model": null, "assignments": [{"subtask_id": "s1", "role": "reasoning", "model": "llama3.1:8b", "agent_id": "reasoning|llama3.1:8b"}], "active_models": ["llama3.1:8b"], "active_role_agents": ["reasoning|llama3.1:8b"]}
{"event": "subtask", "ts_ms": 1772063821681.4854, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-3", "subtask_id": "s1", "task_type": "reasoning", "difficulty": 2.5, "estimated_tokens": 120, "assigned_agent": "llama3.1:8b", "agent_id": "reasoning|llama3.1:8b", "routing_mode": "lp", "estimated_performance": 0.7100000000000001, "estimated_token_cost": 168.0, "estimated_switch_cost_norm": 0.0, "swapped_in_for_job": false, "actual_latency_ms": 225.89134611189365, "input_tokens": 67, "output_tokens": 2, "judge_score": null, "benchmark_name": "workflowbench", "benchmark_score": null, "success": true, "error": null, "output": "NO"}
{"event": "plan_step", "ts_ms": 1772063821689.0107, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-3", "plan_step_index": 2, "routing_mode": "lp", "mpc": true, "horizon_depth": 1, "horizon_nodes": ["s0", "s1", "s2"], "ready_now_nodes": ["s2"], "active_models_before": ["llama3.1:8b"], "gpu_vram_gb": 8.0, "lp_dpp_enabled": true, "lp_solver_name": "HIGHS", "lp_solve_status": "optimal", "lp_solve_time_ms": 0.6709098815917969, "lp_objective_value": 2.004, "assignments": [{"subtask_id": "s0", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.778, "estimated_token_cost": 251.99999999999994, "estimated_switch_cost_share": 0.0}, {"subtask_id": "s1", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.7500000000000001, "estimated_token_cost": 168.0, "estimated_switch_cost_share": 0.0}, {"subtask_id": "s2", "assigned_agent": "llama3.1:8b", "estimated_performance": 0.77, "estimated_token_cost": 168.0, "estimated_switch_cost_share": 0.0}], "executed_assignments": [{"subtask_id": "s2", "assigned_agent": "llama3.1:8b"}], "step_vram_gb": 8.0}
{"event": "orchestration", "ts_ms": 1772063821693.0723, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-3", "benchmark_name": "workflowbench", "routing_mode": "lp", "routing_source": "lp", "planner_model": null, "assignments": [{"subtask_id": "s2", "role": "summarize", "model": "llama3.1:8b", "agent_id": "summarize|llama3.1:8b"}], "active_models": ["llama3.1:8b"], "active_role_agents": ["summarize|llama3.1:8b"]}
{"event": "subtask", "ts_ms": 1772063822008.4163, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-3", "subtask_id": "s2", "task_type": "summarize", "difficulty": 1.5, "estimated_tokens": 120, "assigned_agent": "llama3.1:8b", "agent_id": "summarize|llama3.1:8b", "routing_mode": "lp", "estimated_performance": 0.77, "estimated_token_cost": 168.0, "estimated_switch_cost_norm": 0.0, "swapped_in_for_job": false, "actual_latency_ms": 311.6540424525738, "input_tokens": 57, "output_tokens": 11, "judge_score": null, "benchmark_name": "workflowbench", "benchmark_score": null, "success": true, "error": null, "output": "The WorkflowBench job wb3 was processed."}
{"event": "job", "ts_ms": 1772063822012.573, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-3", "query": "WorkflowBench job wb3", "gpu_name": "NVIDIA A100 80GB PCIe", "gpu_uuid": "GPU-68a0d6f9-97b4-8e27-fbb7-a234eaefd1a8", "benchmark_name": "workflowbench", "routing_mode": "lp", "lambda_token": 0.5, "lambda_switch": 0.2, "gpu_vram_gb": 8.0, "vram_used_gb": 8.0, "vram_violation": false, "loaded_models_before": ["llama3.1:8b"], "active_models": ["llama3.1:8b"], "active_roles": ["extraction", "reasoning", "summarize"], "active_role_agents": ["extraction|llama3.1:8b", "reasoning|llama3.1:8b", "summarize|llama3.1:8b"], "n_distinct_models": 1, "n_role_agents": 3, "models_swapped_in": [], "estimated_switch_cost_ms": 0.0, "sum_token_cost": 0.0, "job_score": 0.3333333333333333, "token_scale": 1000.0, "switch_t_scale_ms": 1500.0}
{"event": "job_costs", "ts_ms": 1772063822016.2183, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-3", "query": "WorkflowBench job wb3", "gpu_name": "NVIDIA A100 80GB PCIe", "gpu_uuid": "GPU-68a0d6f9-97b4-8e27-fbb7-a234eaefd1a8", "benchmark_name": "workflowbench", "routing_mode": "lp", "lambda_token": 0.5, "lambda_switch": 0.2, "gpu_vram_gb": 8.0, "vram_used_gb": 8.0, "vram_violation": false, "loaded_models_before": ["llama3.1:8b"], "active_models": ["llama3.1:8b"], "active_roles": ["extraction", "reasoning", "summarize"], "active_role_agents": ["extraction|llama3.1:8b", "reasoning|llama3.1:8b", "summarize|llama3.1:8b"], "n_distinct_models": 1, "n_role_agents": 3, "models_swapped_in": [], "estimated_switch_cost_ms": 0.0, "sum_token_cost": 315.0, "job_score": 0.3333333333333333, "token_scale": 1000.0, "switch_t_scale_ms": 1500.0}
{"event": "job_dag_summary", "ts_ms": 1772063822019.6145, "run_id": "20260225-235650-31188-lp", "job_id": "workflowbench-3", "benchmark_name": "workflowbench", "routing_mode": "lp", "quality_estimator_type": "static", "is_dag": true, "mpc": true, "horizon_depth": 1, "n_nodes": 3, "n_edges": 2, "n_layers": 3, "n_plan_steps": 3, "vram_peak_gb": 8.0, "peak_vram_used_gb": 8.0, "vram_distinct_gb": 8.0, "total_latency_ms": 846.2591525167227, "total_token_cost": 315.0, "total_switch_cost_est": 0.0, "avg_subtask_score": 0.3333333333333333, "job_score": 0.3333333333333333, "job_success": true, "lp_solver_name": "HIGHS", "lp_solve_time_ms_avg": 0.7379}
